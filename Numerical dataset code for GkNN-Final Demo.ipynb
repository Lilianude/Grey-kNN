{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "410b67b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import os\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d17348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Fill missing values with mean/mode\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class meanModeImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    " \n",
    "    def fit(self, data, y=None):\n",
    "\n",
    "        self.fill = pd.Series([data[c].value_counts().index[0]\n",
    "            if data[c].dtype == np.dtype('O') else data[c].mean() for c in data],\n",
    "            index=data.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, data, y=None):\n",
    "        return data.fillna(self.fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5067934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GKnn Algorithm\n",
    "from numpy import mean\n",
    "from statistics import mode\n",
    "import time\n",
    "\n",
    "def GKnn(impute_df):\n",
    "    \n",
    "    for i in range(len(empty_loc_cols)-1):\n",
    "\n",
    "        ## Differentiate numerical and categorical data\n",
    "        numerical_cols = impute_df._get_numeric_data().columns #fetches just the numeric columns\n",
    "        cols = impute_df.columns                                 # entire columns in dataset\n",
    "        categorical_cols = list(set(cols) - set(numerical_cols)) # gives us just the categorical columns\n",
    "        num_df = impute_df.loc[:,numerical_cols]                 #locates all rows in numerical dataframe column by their labels\n",
    "        cat_df = impute_df.loc[:,categorical_cols]               #locates all columns in categorical dataframe column by their labels\n",
    "        \n",
    "        \n",
    "        num_ck=num_df.iloc[empty_loc_cols[i],:]                  # gets the location/index of emptyelements in a numeric DF\n",
    "        maxIter = 2\n",
    "        num_cp=num_df.copy()\n",
    "        num_cp.drop([i + 1], axis = 0)                           #dropping adjacent emptyrows on indexing for numerical dataset to avoid duplication\n",
    "\n",
    "        cat_ck=cat_df.iloc[empty_loc_cols[i],:]                  # gets the location/index of empty elements in a categorical DF\n",
    "        cat_cp=cat_df.copy()\n",
    "        cat_cp.drop([i + 1], axis = 0)                           # dropping adjacent emptyrows on indexing for categorical dataset to avoid duplictaion\n",
    "        \n",
    "        \n",
    "        def greyRelationalGrade(impute_df):\n",
    "           \n",
    "            t1=pd.DataFrame() #initializing a dataframe\n",
    "            t2=pd.DataFrame(data = None, columns=cat_cp.columns, index=cat_cp.index) #has the shape of the cat_cp dataframe\n",
    "            \n",
    "            for j in range(num_cp.index.size):\n",
    "                temp=pd.Series(num_cp.iloc[j,:]-num_ck)\n",
    "                t1=t1.append(temp,ignore_index=True)\n",
    "                \n",
    "                if(cat_cp.iloc[j,:].equals(cat_ck)):\n",
    "                    t2.iloc[j,:] = 1\n",
    "                else:\n",
    "                    t2.iloc[j,:] = 0\n",
    "\n",
    "            t1.reset_index(drop=True, inplace=True)\n",
    "            t2.reset_index(drop=True, inplace=True)\n",
    "            t = pd.concat([t1, t2], axis=1)\n",
    "\n",
    "                \n",
    "            mmax=t.abs().max().max()\n",
    "            mmin=t.abs().min().min()\n",
    "            rho=0.5\n",
    "\n",
    "            # Computing grey correlation coefficient\n",
    "            GRC=((mmin+rho*mmax)/(abs(t)+rho*mmax))\n",
    "\n",
    "            # Computing the GRG and getting the rank\n",
    "            GRG=GRC.sum(axis=1)/GRC.columns.size\n",
    "            GRGSort = GRG.sort_values(ascending= False)\n",
    "            \n",
    "            return GRGSort\n",
    "        \n",
    " \n",
    "        count = 0\n",
    "        prev = pd.DataFrame(data=incomplete_df.iloc[empty_loc_cols]).mean()\n",
    "        for j in range(len(empty_loc[0])-1):\n",
    "            result= greyRelationalGrade(impute_df)\n",
    "            resultSorted = result.sort_values(ascending = False)\n",
    "            neighbours =  resultSorted.iloc[0:5].index\n",
    "            # find the mean , and most frequent of the values using the index of these instances\n",
    "            values  = impute_df.iloc[neighbours]\n",
    "            num_neigh= values._get_numeric_data().columns\n",
    "            cat_neigh = list(set(values) - set(num_neigh))\n",
    "            cat_neigh_cols = values.loc[:, cat_neigh]\n",
    "            num_neigh_cols = values.loc[:,num_neigh]\n",
    "            nMean = num_neigh_cols.mean(axis = 0)\n",
    "            \n",
    "            ## imputation using k nearest neighbor instances\n",
    "            if(empty_loc_cols[i] == empty_loc[0][j]):\n",
    "                impute_df.iloc[empty_loc[0][j], empty_loc[1][j]] = nMean[len(empty_loc)-1]\n",
    "            count =+ 1\n",
    "            tol = 10e-4   \n",
    "            \n",
    "            ##convergence criteria\n",
    "            if count >= maxIter or max(abs(impute_df.iloc[empty_loc_cols].mean() - prev )) < tol:\n",
    "                break\n",
    "            prev = impute_df.iloc[empty_loc_cols].mean()\n",
    "    \n",
    "    return impute_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a769f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute NRMS\n",
    "\n",
    "from sklearn import metrics\n",
    "#Frobenius Function\n",
    "def frob(x):\n",
    "    return np.linalg.norm(x, 'fro')\n",
    "\n",
    "#NRMS\n",
    "def nrms(original, imputed):\n",
    "    x = frob(imputed - original) / frob(original)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "436eda4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import xlsx files as pandas dataframe\n",
    "pathIncomplete = '/Users/lilianude/Documents/UDE LILIAN/GENG 8900 Data Mining/Datasets/Incomplete Datasets Without Labels/Final Demo Num'\n",
    "complete_df = pd.read_excel('/Users/lilianude/Documents/UDE LILIAN/GENG 8900 Data Mining/Datasets/Original Datasets Without Labels/PID.xlsx', header = None)\n",
    "incomplete_df_name_list = []\n",
    "incomplete_df_list = []\n",
    "for filename in os.listdir(pathIncomplete):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        incomplete_df_list.append(pd.read_excel(pathIncomplete+\"/\"+filename, header=None))\n",
    "        incomplete_df_name_list.append(filename.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f8fccd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PID_AE_10.xlsx', '.DS_Store']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(pathIncomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dcf9b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'PID_AE_10': 0.28581014869847443}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df_list = []\n",
    "nrms_data = []\n",
    "index = 0\n",
    "for incomplete_df in incomplete_df_list:\n",
    "\n",
    "    incomplete_df.reset_index()\n",
    "    complete_df.reset_index()\n",
    "    \n",
    "    complete_df.columns=[\"Col\"+str(i) for i in range(complete_df.shape[1])] # gives an arrary size of column count\n",
    "    incomplete_df.columns=[\"Col\"+str(i) for i in range(incomplete_df.shape[1])] # gives array size of column count(incompleteDF)\n",
    "    \n",
    "    ## find empty locations\n",
    "    empty_loc = np.where(pd.isnull(incomplete_df))\n",
    "    empty_loc_cols = np.unique(empty_loc[0])\n",
    "    empty_loc_col = np.unique(empty_loc[1])\n",
    "    \n",
    "   \n",
    "\n",
    "    ## Replace NaN values to mean values\n",
    "    incomplete_df = meanModeImputer().fit_transform(incomplete_df)\n",
    "    \n",
    "    ## GKnn\n",
    "    imputed_df = GKnn(incomplete_df)\n",
    "    \n",
    "    #Compute NRMS\n",
    "    nrmser = nrms(complete_df, imputed_df)\n",
    "    nrms_data.append({incomplete_df_name_list[index]: nrmser})\n",
    "    \n",
    "    imputed_df_list.append(imputed_df)\n",
    "    index+=1\n",
    "    \n",
    "nrms_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77ed3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save imputed dataframes to xlsx\n",
    "index = 0\n",
    "for df in imputed_df_list:\n",
    "    df.to_excel(\"/Users/lilianude/Documents/UDE LILIAN/GENG 8900 Data Mining/Datasets/Graph/Iris_K7/\"+incomplete_df_name_list[index]+\".xlsx\")\n",
    "    index+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a72b97e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PID_AE_10': 0.28581014869847443}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Dictionary of dataset_name : nrms_values\n",
    "nrms_dict = {}\n",
    "index = 0\n",
    "for imputed_df in imputed_df_list:\n",
    "    nrmser = nrms(complete_df, imputed_df)\n",
    "    nrms_dict.update( {incomplete_df_name_list[index]: nrmser} )\n",
    "    index+=1\n",
    "nrms_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "468c9b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Dictionary as csv file\n",
    "import csv\n",
    "with open('/Users/lilianude/Documents/UDE LILIAN/GENG 8900 Data Mining/Datasets/Graph/NRMS_AE/NRMS/Iris_k7.csv', 'w') as csv_file:  \n",
    "    writeTo = csv.writer(csv_file)\n",
    "    for key, value in nrms_dict.items():\n",
    "        writeTo.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03d1bb9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'PID_AE_10': 0.28581014869847443}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrms_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94f52890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[     Col0        Col1   Col2  Col3        Col4        Col5   Col6        Col7\n",
       " 0     6.0  148.000000  150.0  35.0  150.000000  150.000000  0.627  150.000000\n",
       " 1     1.0   85.000000   66.0  29.0    0.000000   26.600000  0.351   31.000000\n",
       " 2     8.0  183.000000   64.0   0.0    0.000000   23.300000  0.672   32.000000\n",
       " 3     1.0   89.000000   66.0  23.0   94.000000   28.100000  0.167   21.000000\n",
       " 4     0.0  120.596821   40.0  35.0   77.716535   31.909134  2.288   33.406728\n",
       " ..    ...         ...    ...   ...         ...         ...    ...         ...\n",
       " 763  10.0  101.000000   76.0  48.0  180.000000   32.900000  0.171   63.000000\n",
       " 764   2.0  122.000000   70.0  27.0    0.000000   36.800000  0.340   27.000000\n",
       " 765   5.0  121.000000   72.0  23.0  112.000000   26.200000  0.245   30.000000\n",
       " 766   1.0  126.000000   60.0   0.0    0.000000   30.100000  0.349   47.000000\n",
       " 767   1.0   93.000000   70.0  31.0    0.000000   30.400000  0.315   23.000000\n",
       " \n",
       " [768 rows x 8 columns]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867216fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
