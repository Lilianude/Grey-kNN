{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "410b67b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import os\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d17348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill missing values with mean and mode\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class meanModeImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5067934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GKnn Algorithm\n",
    "from numpy import mean\n",
    "from statistics import mode\n",
    "import time\n",
    "\n",
    "def GKnn(impute_df):\n",
    "    \n",
    "    for i in range(len(empty_loc_cols)-1):\n",
    "\n",
    "        ## Differentiate numerical and categorical data\n",
    "        numerical_cols = impute_df._get_numeric_data().columns #fetches just the numeric columns\n",
    "        cols = impute_df.columns                                 # entire columns in dataset\n",
    "        categorical_cols = list(set(cols) - set(numerical_cols)) # gives us just the categorical columns\n",
    "        num_df = impute_df.loc[:,numerical_cols]                 #locates all rows in numerical dataframe column by their labels\n",
    "        cat_df = impute_df.loc[:,categorical_cols]               #locates all columns in categorical dataframe column by their labels\n",
    "        \n",
    "        num_ck=num_df.iloc[empty_loc_cols[i],:]                  # gets the location/index of emptyelements in a numeric DF\n",
    "        maxIter = 2\n",
    "        num_cp=num_df.copy()\n",
    "        num_cp.drop([i + 1], axis = 0)                           #dropping adjacent emptyrows on indexing for numerical dataset to avoid duplication\n",
    "\n",
    "        cat_ck=cat_df.iloc[empty_loc_cols[i],:]                  # gets the location/index of empty elements in a categorical DF\n",
    "        cat_cp=cat_df.copy()\n",
    "        cat_cp.drop([i + 1], axis = 0)                           # dropping adjacent emptyrows on indexing for categorical dataset to avoid duplictaion\n",
    "        \n",
    "        \n",
    "        def greyRelationalGrade(impute_df):\n",
    "           \n",
    "            t1=pd.DataFrame() #initializing a dataframe\n",
    "            t2=pd.DataFrame(data = None, columns=cat_cp.columns, index=cat_cp.index) #has the shape of the cat_cp dataframe\n",
    "            \n",
    "            for j in range(num_cp.index.size):\n",
    "                temp=pd.Series(num_cp.iloc[j,:]-num_ck)\n",
    "                t1=t1.append(temp,ignore_index=True)\n",
    "                \n",
    "                if(cat_cp.iloc[j,:].equals(cat_ck)):\n",
    "                    t2.iloc[j,:] = 1\n",
    "                else:\n",
    "                    t2.iloc[j,:] = 0\n",
    "            t1.reset_index(drop=True, inplace=True)\n",
    "            t2.reset_index(drop=True, inplace=True)\n",
    "            t = pd.concat([t1, t2], axis=1)  \n",
    "            mmax=t.abs().max().max()\n",
    "            mmin=t.abs().min().min()\n",
    "            rho=0.5\n",
    "\n",
    "            # Computing grey correlation coefficient\n",
    "            GRC=((mmin+rho*mmax)/(abs(t)+rho*mmax))\n",
    "\n",
    "            # Computing the GRG and getting the rank\n",
    "            GRG=GRC.sum(axis=1)/GRC.columns.size\n",
    "            GRGSort = GRG.sort_values(ascending= False)\n",
    "            \n",
    "            return GRGSort\n",
    "        \n",
    " \n",
    "        count = 0\n",
    "        prev = pd.DataFrame(data=incomplete_df.iloc[empty_loc_cols]).mean()\n",
    "        for j in range(len(empty_loc[0])-1):\n",
    "            startTime = time.time()\n",
    "            result= greyRelationalGrade(impute_df)\n",
    "            resultSorted = result.sort_values(ascending = False)\n",
    "            neighbours =  resultSorted.iloc[0:15].index\n",
    "            # find the mean , and most frequent of the values using the index of these instances\n",
    "            values  = impute_df.iloc[neighbours]\n",
    "            num_neigh= values._get_numeric_data().columns\n",
    "            cat_neigh = list(set(values) - set(num_neigh))\n",
    "            cat_neigh_cols = values.loc[:, cat_neigh]\n",
    "            num_neigh_cols = values.loc[:,num_neigh]\n",
    "            nMean = num_neigh_cols.mean(axis = 0)\n",
    "            nMode = cat_neigh_cols.value_counts().index\n",
    "                        \n",
    "            ## imputation using k nearest neighbor instances\n",
    "            if(empty_loc_cols[i] == empty_loc[0][j]):\n",
    "            \n",
    "                if empty_loc_cols[i] in cat_neigh_cols :\n",
    "                    impute_df.iloc[empty_loc[0][j], empty_loc[1][j]] = nMode[len(empty_loc_col)-1]  \n",
    "                    \n",
    "                elif empty_loc_cols[i] in num_neigh_cols:\n",
    "                    impute_df.iloc[empty_loc[0],[j], empty_loc[1][j]] = nMean[len(empty_loc_col)-1]\n",
    "            count += 1\n",
    "            tol = 10e-4\n",
    "           \n",
    "            ## convergence criteria\n",
    "            if max(abs(impute_df.iloc[empty_loc_cols].mean() - prev)) <= tol or count >= maxIter: \n",
    "                break\n",
    "            prev = impute_df.iloc[empty_loc_cols].mean()\n",
    "            \n",
    "    return impute_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a769f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute NRMS\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "#Frobenius Functiom\n",
    "def frob(x):\n",
    "    return np.linalg.norm(x, 'fro')\n",
    "\n",
    "#NRMS\n",
    "def nrms(original, imputed):\n",
    "    x = frob(imputed - original) / frob(original)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "436eda4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import xlsx files as pandas dataframe\n",
    "pathIncomplete = '/Users/lilianude/Documents/UDE LILIAN/GENG 8900 Data Mining/Datasets/Incomplete Datasets Without Labels/Final Project'\n",
    "complete_df = pd.read_excel('/Users/lilianude/Documents/UDE LILIAN/GENG 8900 Data Mining/Datasets/Original Datasets Without Labels/Aheart.xlsx', header = None)\n",
    "incomplete_df_name_list = []\n",
    "incomplete_df_list = []\n",
    "for filename in os.listdir(pathIncomplete):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        incomplete_df_list.append(pd.read_excel(pathIncomplete+\"/\"+filename, header=None))\n",
    "        incomplete_df_name_list.append(filename.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a2de1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aheart_C_20']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incomplete_df_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7dcf9b63",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-500e9e559219>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m## GKnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mimputed_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGKnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincomplete_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mnumerical_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputed_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_numeric_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-3243ded3eeb9>\u001b[0m in \u001b[0;36mGKnn\u001b[0;34m(impute_df)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty_loc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mstartTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgreyRelationalGrade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimpute_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mresultSorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mneighbours\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mresultSorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-3243ded3eeb9>\u001b[0m in \u001b[0;36mgreyRelationalGrade\u001b[0;34m(impute_df)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# Computing the GRG and getting the rank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mGRG\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGRC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mGRC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mGRGSort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGRG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mGRGSort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   3261\u001b[0m         \u001b[0;31m# GH 35922. Make sorting stable by leveraging nargsort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m         \u001b[0mvalues_to_sort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_key_mapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3263\u001b[0;31m         \u001b[0msorted_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnargsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues_to_sort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3265\u001b[0m         result = self._constructor(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/sorting.py\u001b[0m in \u001b[0;36mnargsort\u001b[0;34m(items, kind, ascending, na_position, key, mask)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# na_position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mna_position\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"last\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mna_position\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"first\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnan_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "imputed_df_list = []\n",
    "nrms_data = {}\n",
    "ae_data = {}\n",
    "index = 0\n",
    "for incomplete_df in incomplete_df_list:\n",
    "\n",
    "    incomplete_df.reset_index()\n",
    "    complete_df.reset_index()\n",
    "    \n",
    "    complete_df.columns=[\"Col\"+str(i) for i in range(complete_df.shape[1])]     #added header to the columns\n",
    "    incomplete_df.columns=[\"Col\"+str(i) for i in range(incomplete_df.shape[1])] #added header to the columns\n",
    "    \n",
    "    ## find empty locations\n",
    "    numerical_cols = incomplete_df._get_numeric_data().columns\n",
    "    cols = incomplete_df.columns\n",
    "    categorical_cols = list(set(cols) - set(numerical_cols))\n",
    "    cat_empty_loc = np.where(pd.isnull(incomplete_df.loc[:,categorical_cols]))   #categorical empty locations\n",
    "    \n",
    "    empty_loc = np.where(pd.isnull(incomplete_df))\n",
    "    empty_loc_cols = np.unique(empty_loc[0])\n",
    "    empty_loc_col = np.unique(empty_loc[1])\n",
    "    \n",
    "    ## Replace NaN values to mean values\n",
    "    incomplete_df = meanModeImputer().fit_transform(incomplete_df)\n",
    "    \n",
    "    ## GKnn\n",
    "    imputed_df = GKnn(incomplete_df)\n",
    "    \n",
    "    numerical_cols = imputed_df._get_numeric_data().columns\n",
    "    cols = imputed_df.columns\n",
    "    categorical_cols = list(set(cols) - set(numerical_cols))\n",
    "    imputed_num_df = imputed_df.loc[:,numerical_cols]        #numerical dataframe of the imputed data\n",
    "    imputed_cat_df = imputed_df.loc[:,categorical_cols]      #categorical dataframe of the imputed data\n",
    "    complete_num_df = complete_df.loc[:,numerical_cols]        #numerical dataframe of the original data\n",
    "    complete_cat_df = complete_df.loc[:,categorical_cols]      # categorical dataframe of the original data\n",
    "        \n",
    "        \n",
    "    ## Compute NRMS\n",
    "    nrmser = nrms(complete_num_df, imputed_num_df)\n",
    "    nrms_data.update({incomplete_df_name_list[index]: nrmser})\n",
    "\n",
    "   ## Compute AE\n",
    "    imputed_ae = 0\n",
    "    for x in range(len(cat_empty_loc[0]) - 1):\n",
    "        if(imputed_cat_df.iloc[cat_empty_loc[0][x], cat_empty_loc[1][x]] == complete_cat_df.iloc[cat_empty_loc[0][x], cat_empty_loc[1][x]]):\n",
    "            imputed_ae+=1\n",
    "    AE = (complete_cat_df.size - len(cat_empty_loc[0]) + imputed_ae) / complete_cat_df.size\n",
    "    ae_data.update( {incomplete_df_name_list[index]: AE} )\n",
    "    \n",
    "    imputed_df_list.append(imputed_df)\n",
    "    index+=1\n",
    "   \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "ae_data    \n",
    "nrms_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ed3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save imputed dataframes to xlsx\n",
    "index = 0\n",
    "for df in imputed_df_list:\n",
    "    df.to_excel(\"/Users/lilianude/Documents/UDE LILIAN/GENG 8900 Data Mining/Datasets/Graph/Aheart_K7/\"+incomplete_df_name_list[index]+\".xlsx\")\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45426721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Dictionary as csv file\n",
    "import csv\n",
    "with open('/Users/lilianude/Documents/UDE LILIAN/GENG 8900 Data Mining/Datasets/Graph/NRMS_AE/NRMS/Aheart_k7.csv', 'w') as csv_file:  \n",
    "    writeTo = csv.writer(csv_file)\n",
    "    for key, value in nrms_data.items():\n",
    "        writeTo.writerow([key, value])\n",
    "\n",
    "    \n",
    "with open('/Users/lilianude/Documents/UDE LILIAN/GENG 8900 Data Mining/Datasets/Graph/NRMS_AE/AE/Aheart_ae_k7.csv', 'w') as csv_file:  \n",
    "    writeTo = csv.writer(csv_file)\n",
    "    for key, value in ae_data.items():\n",
    "        writeTo.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d1bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daf1aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrms_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f52890",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
