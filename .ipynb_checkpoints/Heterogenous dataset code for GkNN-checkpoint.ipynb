{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "410b67b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import os\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d17348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill missing values with mean and mode\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class meanModeImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5067934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GKnn Algorithm\n",
    "from numpy import mean\n",
    "from statistics import mode\n",
    "import time\n",
    "\n",
    "def GKnn(impute_df):\n",
    "    \n",
    "    for i in range(len(empty_loc_cols)-1):\n",
    "\n",
    "        ## Differentiate numerical and categorical data\n",
    "        numerical_cols = impute_df._get_numeric_data().columns #fetches just the numeric columns\n",
    "        cols = impute_df.columns                                 # entire columns in dataset\n",
    "        categorical_cols = list(set(cols) - set(numerical_cols)) # gives us just the categorical columns\n",
    "        num_df = impute_df.loc[:,numerical_cols]                 #locates all rows in numerical dataframe column by their labels\n",
    "        cat_df = impute_df.loc[:,categorical_cols]               #locates all columns in categorical dataframe column by their labels\n",
    "        \n",
    "        num_ck=num_df.iloc[empty_loc_cols[i],:]                  # gets the location/index of emptyelements in a numeric DF\n",
    "        maxIter = 2\n",
    "        num_cp=num_df.copy()\n",
    "        num_cp.drop([i + 1], axis = 0)                           #dropping adjacent emptyrows on indexing for numerical dataset to avoid duplication\n",
    "\n",
    "        cat_ck=cat_df.iloc[empty_loc_cols[i],:]                  # gets the location/index of empty elements in a categorical DF\n",
    "        cat_cp=cat_df.copy()\n",
    "        cat_cp.drop([i + 1], axis = 0)                           # dropping adjacent emptyrows on indexing for categorical dataset to avoid duplictaion\n",
    "        \n",
    "        \n",
    "        def greyRelationalGrade(impute_df):\n",
    "           \n",
    "            t1=pd.DataFrame() #initializing a dataframe\n",
    "            t2=pd.DataFrame(data = None, columns=cat_cp.columns, index=cat_cp.index) #has the shape of the cat_cp dataframe\n",
    "            \n",
    "            for j in range(num_cp.index.size):\n",
    "                temp=pd.Series(num_cp.iloc[j,:]-num_ck)\n",
    "                t1=t1.append(temp,ignore_index=True)\n",
    "                \n",
    "                if(cat_cp.iloc[j,:].equals(cat_ck)):\n",
    "                    t2.iloc[j,:] = 1\n",
    "                else:\n",
    "                    t2.iloc[j,:] = 0\n",
    "            t1.reset_index(drop=True, inplace=True)\n",
    "            t2.reset_index(drop=True, inplace=True)\n",
    "            t = pd.concat([t1, t2], axis=1)  \n",
    "            mmax=t.abs().max().max()\n",
    "            mmin=t.abs().min().min()\n",
    "            rho=0.5\n",
    "\n",
    "            # Computing grey correlation coefficient\n",
    "            GRC=((mmin+rho*mmax)/(abs(t)+rho*mmax))\n",
    "\n",
    "            # Computing the GRG and getting the rank\n",
    "            GRG=GRC.sum(axis=1)/GRC.columns.size\n",
    "            GRGSort = GRG.sort_values(ascending= False)\n",
    "            \n",
    "            return GRGSort\n",
    "        \n",
    " \n",
    "        count = 0\n",
    "        prev = pd.DataFrame(data=incomplete_df.iloc[empty_loc_cols]).mean()\n",
    "        for j in range(len(empty_loc[0])-1):\n",
    "            startTime = time.time()\n",
    "            result= greyRelationalGrade(impute_df)\n",
    "            resultSorted = result.sort_values(ascending = False)\n",
    "            neighbours =  resultSorted.iloc[0:15].index\n",
    "            # find the mean , and most frequent of the values using the index of these instances\n",
    "            values  = impute_df.iloc[neighbours]\n",
    "            num_neigh= values._get_numeric_data().columns\n",
    "            cat_neigh = list(set(values) - set(num_neigh))\n",
    "            cat_neigh_cols = values.loc[:, cat_neigh]\n",
    "            num_neigh_cols = values.loc[:,num_neigh]\n",
    "            nMean = num_neigh_cols.mean(axis = 0)\n",
    "            nMode = cat_neigh_cols.value_counts().index\n",
    "                        \n",
    "            ## imputation using k nearest neighbor instances\n",
    "            if(empty_loc_cols[i] == empty_loc[0][j]):\n",
    "            \n",
    "                if empty_loc_cols[i] in cat_neigh_cols :\n",
    "                    impute_df.iloc[empty_loc[0][j], empty_loc[1][j]] = nMode[len(empty_loc_col)-1]  \n",
    "                    \n",
    "                elif empty_loc_cols[i] in num_neigh_cols:\n",
    "                    impute_df.iloc[empty_loc[0],[j], empty_loc[1][j]] = nMean[len(empty_loc_col)-1]\n",
    "            count += 1\n",
    "            tol = 10e-4\n",
    "           \n",
    "            ## convergence criteria\n",
    "            if max(abs(impute_df.iloc[empty_loc_cols].mean() - prev)) <= tol or count >= maxIter: \n",
    "                break\n",
    "            prev = impute_df.iloc[empty_loc_cols].mean()\n",
    "            \n",
    "    return impute_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a769f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute NRMS\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "#Frobenius Functiom\n",
    "def frob(x):\n",
    "    return np.linalg.norm(x, 'fro')\n",
    "\n",
    "#NRMS\n",
    "def nrms(original, imputed):\n",
    "    x = frob(imputed - original) / frob(original)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "436eda4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import xlsx files as pandas dataframe\n",
    "pathIncomplete = '/Users/lilianude/Documents/UDE LILIAN/GENG 8900 Data Mining/Datasets/Incomplete Datasets Without Labels/Final Project'\n",
    "complete_df = pd.read_excel('/Users/lilianude/Documents/UDE LILIAN/GENG 8900 Data Mining/Datasets/Original Datasets Without Labels/Aheart.xlsx', header = None)\n",
    "incomplete_df_name_list = []\n",
    "incomplete_df_list = []\n",
    "for filename in os.listdir(pathIncomplete):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        incomplete_df_list.append(pd.read_excel(pathIncomplete+\"/\"+filename, header=None))\n",
    "        incomplete_df_name_list.append(filename.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a2de1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aheart_NW_5']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incomplete_df_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dcf9b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Aheart_NW_5': 0.9805194805194806}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df_list = []\n",
    "nrms_data = {}\n",
    "ae_data = {}\n",
    "index = 0\n",
    "for incomplete_df in incomplete_df_list:\n",
    "\n",
    "    incomplete_df.reset_index()\n",
    "    complete_df.reset_index()\n",
    "    \n",
    "    complete_df.columns=[\"Col\"+str(i) for i in range(complete_df.shape[1])]     #added header to the columns\n",
    "    incomplete_df.columns=[\"Col\"+str(i) for i in range(incomplete_df.shape[1])] #added header to the columns\n",
    "    \n",
    "    ## find empty locations\n",
    "    numerical_cols = incomplete_df._get_numeric_data().columns\n",
    "    cols = incomplete_df.columns\n",
    "    categorical_cols = list(set(cols) - set(numerical_cols))\n",
    "    cat_empty_loc = np.where(pd.isnull(incomplete_df.loc[:,categorical_cols]))   #categorical empty locations\n",
    "    \n",
    "    empty_loc = np.where(pd.isnull(incomplete_df))\n",
    "    empty_loc_cols = np.unique(empty_loc[0])\n",
    "    empty_loc_col = np.unique(empty_loc[1])\n",
    "    \n",
    "    ## Replace NaN values to mean values\n",
    "    incomplete_df = meanModeImputer().fit_transform(incomplete_df)\n",
    "    \n",
    "    ## GKnn\n",
    "    imputed_df = GKnn(incomplete_df)\n",
    "    \n",
    "    numerical_cols = imputed_df._get_numeric_data().columns\n",
    "    cols = imputed_df.columns\n",
    "    categorical_cols = list(set(cols) - set(numerical_cols))\n",
    "    imputed_num_df = imputed_df.loc[:,numerical_cols]        #numerical dataframe of the imputed data\n",
    "    imputed_cat_df = imputed_df.loc[:,categorical_cols]      #categorical dataframe of the imputed data\n",
    "    complete_num_df = complete_df.loc[:,numerical_cols]        #numerical dataframe of the original data\n",
    "    complete_cat_df = complete_df.loc[:,categorical_cols]      # categorical dataframe of the original data\n",
    "        \n",
    "        \n",
    "    ## Compute NRMS\n",
    "    nrmser = nrms(complete_num_df, imputed_num_df)\n",
    "    nrms_data.update({incomplete_df_name_list[index]: nrmser})\n",
    "\n",
    "   ## Compute AE\n",
    "    imputed_ae = 0\n",
    "    for x in range(len(cat_empty_loc[0]) - 1):\n",
    "        if(imputed_cat_df.iloc[cat_empty_loc[0][x], cat_empty_loc[1][x]] == complete_cat_df.iloc[cat_empty_loc[0][x], cat_empty_loc[1][x]]):\n",
    "            imputed_ae+=1\n",
    "    AE = (complete_cat_df.size - len(cat_empty_loc[0]) + imputed_ae) / complete_cat_df.size\n",
    "    ae_data.update( {incomplete_df_name_list[index]: AE} )\n",
    "    \n",
    "    imputed_df_list.append(imputed_df)\n",
    "    index+=1\n",
    "   \n",
    "    \n",
    "nrms_data\n",
    "  \n",
    "ae_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77ed3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save imputed dataframes to xlsx\n",
    "index = 0\n",
    "for df in imputed_df_list:\n",
    "    df.to_excel(\"/Users/lilianude/Documents/UDE LILIAN/GENG 8900 Data Mining/Datasets/Graph/Aheart_K7/\"+incomplete_df_name_list[index]+\".xlsx\")\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45426721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Dictionary as csv file\n",
    "import csv\n",
    "with open('/Users/lilianude/Documents/UDE LILIAN/GENG 8900 Data Mining/Datasets/Graph/NRMS_AE/NRMS/Aheart_k7.csv', 'w') as csv_file:  \n",
    "    writeTo = csv.writer(csv_file)\n",
    "    for key, value in nrms_data.items():\n",
    "        writeTo.writerow([key, value])\n",
    "\n",
    "    \n",
    "with open('/Users/lilianude/Documents/UDE LILIAN/GENG 8900 Data Mining/Datasets/Graph/NRMS_AE/AE/Aheart_ae_k7.csv', 'w') as csv_file:  \n",
    "    writeTo = csv.writer(csv_file)\n",
    "    for key, value in ae_data.items():\n",
    "        writeTo.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03d1bb9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Aheart_NW_5': 0.9805194805194806}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4daf1aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Aheart_NW_5': 0.05996314476067403}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrms_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94f52890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[      Col0   Col1   Col2   Col3     Col4       Col5      Col6       Col7  \\\n",
       " 0    160.0  12.00   5.73  23.11  Present  49.000000  25.30000  97.200000   \n",
       " 1    144.0   0.01   4.41  28.61   Absent  55.000000  28.87000   2.060000   \n",
       " 2    118.0   0.08   3.48  32.28  Present  52.000000  25.98887  17.428612   \n",
       " 3    170.0   7.50   6.41  38.03  Present  51.000000  31.99000  17.428612   \n",
       " 4    134.0  13.60   3.50  27.78  Present  60.000000  25.99000  57.340000   \n",
       " ..     ...    ...    ...    ...      ...        ...       ...        ...   \n",
       " 457  214.0   0.40   5.98  31.72   Absent  64.000000  28.45000   0.000000   \n",
       " 458  182.0   4.20   4.41  32.10   Absent  52.000000  28.61000  18.720000   \n",
       " 459  108.0   3.00   1.59  15.23   Absent  53.061364  20.09000  26.640000   \n",
       " 460  118.0   5.40  11.61  30.79   Absent  64.000000  27.35000  23.970000   \n",
       " 461  132.0   0.00   4.82  33.41  Present  53.061364  14.70000   0.000000   \n",
       " \n",
       "           Col8  \n",
       " 0    52.000000  \n",
       " 1    63.000000  \n",
       " 2    46.000000  \n",
       " 3    58.000000  \n",
       " 4    49.000000  \n",
       " ..         ...  \n",
       " 457  42.807095  \n",
       " 458  52.000000  \n",
       " 459  55.000000  \n",
       " 460  40.000000  \n",
       " 461  46.000000  \n",
       " \n",
       " [462 rows x 9 columns]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb2310e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
